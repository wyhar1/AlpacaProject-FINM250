{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "SET UP\n",
    "--------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import alpaca_trade_api as tradeapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, Sequence, Union\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Status: ACTIVE\n",
      "Buying Power: $200000\n"
     ]
    }
   ],
   "source": [
    "# Alpaca set up\n",
    "\n",
    "# We don't have to hard code these in, but we can for now\n",
    "ALPACA_API_KEY = \"PKSRU8TI6JTHJG0KF87R\"\n",
    "ALPACA_SECRET_KEY = \"goumjgb1Ua9JZ5jpgF9iWiM07GJcCiXnwftYq8My\" \n",
    "ALPACA_BASE_URL = \"https://paper-api.alpaca.markets\"  \n",
    "\n",
    "\n",
    "api = tradeapi.REST(\n",
    "    ALPACA_API_KEY,\n",
    "    ALPACA_SECRET_KEY,\n",
    "    ALPACA_BASE_URL,\n",
    "    api_version='v2'\n",
    ")\n",
    "\n",
    "# Test connection\n",
    "account = api.get_account()\n",
    "print(f\"Account Status: {account.status}\")\n",
    "print(f\"Buying Power: ${account.buying_power}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "CREATE FUNCTIONS\n",
    "----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alternate way to get data by using alpaca instead (since we're just using daily data now)\n",
    "def get_live_data(symbol, lookback_days=2520):  # ~10 years\n",
    "    end = pd.Timestamp.now()\n",
    "    start = end - pd.Timedelta(days=lookback_days)\n",
    "    \n",
    "    # Get historical data from Alpaca\n",
    "    bars = api.get_bars(\n",
    "        symbol,\n",
    "        tradeapi.TimeFrame.Day,\n",
    "        start=start.isoformat(),\n",
    "        end=end.isoformat()\n",
    "    ).df\n",
    "    \n",
    "    return bars['close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FUNCTIONS FOR CREATING A BUNCH OF TECHNICAL INDICATORS\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _safe_div(a, b):\n",
    "    out = np.divide(a, b, out=np.full_like(a, np.nan, dtype=\"float64\"), where=(b != 0) & np.isfinite(b))\n",
    "    return out\n",
    "\n",
    "def _ensure_series(close: Union[pd.Series, pd.DataFrame], name=\"close\") -> pd.Series:\n",
    "    if isinstance(close, pd.DataFrame):\n",
    "        if \"Close\" in close.columns:\n",
    "            close = close[\"Close\"]\n",
    "        elif close.shape[1] == 1:\n",
    "            close = close.iloc[:, 0]\n",
    "        else:\n",
    "            raise ValueError(\"If you pass a DataFrame, it must have a 'Close' column or one column only.\")\n",
    "    close = pd.Series(close, name=name).astype(\"float64\")\n",
    "    close.index = pd.to_datetime(close.index)\n",
    "    return close.sort_index()\n",
    "\n",
    "def _mac(a, span):\n",
    "    # Pandas ewm mean with common trading practice settings\n",
    "    return pd.Series(a).ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "\n",
    "def _rsi(close: pd.Series, window: int) -> pd.Series:\n",
    "    # Close-only RSI (Wilder’s)\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0.0)\n",
    "    down = -delta.clip(upper=0.0)\n",
    "    rs = up.ewm(alpha=1/window, adjust=False, min_periods=window).mean() / \\\n",
    "         down.ewm(alpha=1/window, adjust=False, min_periods=window).mean()\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def _rolling_percentile_rank(x: np.ndarray) -> float:\n",
    "    # rank of last point within window (right-sided, ties -> max rank), scaled [0,1]\n",
    "    arr = np.sort(x)\n",
    "    r = np.searchsorted(arr, x[-1], side=\"right\")\n",
    "    return r / len(x)\n",
    "\n",
    "def _rolling_pos_in_range(close: pd.Series, window: int) -> pd.Series:\n",
    "    roll_max = close.rolling(window, min_periods=window).max()\n",
    "    roll_min = close.rolling(window, min_periods=window).min()\n",
    "    return _safe_div((close - roll_min).to_numpy(), (roll_max - roll_min).to_numpy())\n",
    "\n",
    "def _macd(close: pd.Series, fast: int, slow: int, signal: int):\n",
    "    ema_fast = close.ewm(span=fast, adjust=False, min_periods=fast).mean()\n",
    "    ema_slow = close.ewm(span=slow, adjust=False, min_periods=slow).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    sig = macd.ewm(span=signal, adjust=False, min_periods=signal).mean()\n",
    "    hist = macd - sig\n",
    "    return macd, sig, hist\n",
    "\n",
    "def _dema(close: pd.Series, span: int) -> pd.Series:\n",
    "    ema = close.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "    ema_ema = ema.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "    return 2 * ema - ema_ema\n",
    "\n",
    "def _tema(close: pd.Series, span: int) -> pd.Series:\n",
    "    e1 = close.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "    e2 = e1.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "    e3 = e2.ewm(span=span, adjust=False, min_periods=span).mean()\n",
    "    return 3 * (e1 - e2) + e3\n",
    "\n",
    "# ---------- main ----------\n",
    "def build_tech_indicators(\n",
    "    close: Union[pd.Series, pd.DataFrame],\n",
    "    macro: Optional[pd.DataFrame] = None,\n",
    "    *,\n",
    "    ma_windows: Sequence[int] = (\n",
    "        3,5,7,9,10,12,14,15,18,20,21,24,30,34,35,40,45,50,55,60,63,70,75,80,90,100,120,126,150,180,200,210,220,240,250,252\n",
    "    ),\n",
    "    roc_periods: Sequence[int] = (\n",
    "        1,2,3,4,5,7,9,10,12,14,15,20,21,30,35,40,45,50,60,63,90,120,126,150,180,200,252\n",
    "    ),\n",
    "    rsi_windows: Sequence[int] = (6,7,9,10,12,14,20,21,28),\n",
    "    bb_windows: Sequence[int] = (20,50,100),\n",
    "    bb_k: float = 2.0,\n",
    "    ewm_vol_windows: Sequence[int] = (10,20,21,30,50,63),\n",
    "    acf_windows: Sequence[int] = (21,63,126),\n",
    "    acf_lags: Sequence[int] = (1,2,3,4,5),\n",
    "    skew_kurt_windows: Sequence[int] = (21,63,126,252),\n",
    "    dd_windows: Sequence[int] = (21,63,126,252),\n",
    "    pos_range_windows: Sequence[int] = (10,20,50,100,252),\n",
    "    dema_tema_windows: Sequence[int] = (10,12,14,20,21,30,35,50,63,100),\n",
    "    sharpe_windows: Sequence[int] = (21,63,126,252),\n",
    "    macro_lags: Sequence[int] = (1,5,10),\n",
    "    macro_windows: Sequence[int] = (5,21,63,126,252),\n",
    "    dropna: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a wide feature matrix of technical indicators from close prices and optional macro series.\n",
    "    Parameters\n",
    "    ----------\n",
    "    close : pd.Series or DataFrame\n",
    "        Close prices (datetime index). If DataFrame, must include 'Close' or have 1 column.\n",
    "    macro : pd.DataFrame, optional\n",
    "        Exogenous series (e.g., VIX). Columns = variables, datetime index. Aligned to 'close'.\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Time-indexed feature DataFrame.\n",
    "    \"\"\"\n",
    "    close = _ensure_series(close, name=\"close\")\n",
    "    idx = close.index\n",
    "    feats = pd.DataFrame(index=idx)\n",
    "\n",
    "    # Basic transforms\n",
    "    logp = np.log(close)\n",
    "    ret1 = logp.diff()                   # log return t/t-1\n",
    "    feats[\"ret_1\"] = ret1\n",
    "\n",
    "    # Multi-horizon ROC (simple returns) and log returns\n",
    "    for p in roc_periods:\n",
    "        feats[f\"roc_{p}\"] = close.pct_change(p)\n",
    "        feats[f\"logret_{p}\"] = logp.diff(p)\n",
    "\n",
    "    # Moving averages, EMA, rolling std, z-score, distance-to-MA\n",
    "    for w in ma_windows:\n",
    "        sma = close.rolling(w, min_periods=w).mean()\n",
    "        ema = close.ewm(span=w, adjust=False, min_periods=w).mean()\n",
    "        std = close.rolling(w, min_periods=w).std()\n",
    "        feats[f\"sma_{w}\"] = sma\n",
    "        feats[f\"ema_{w}\"] = ema\n",
    "        feats[f\"std_{w}\"] = std\n",
    "        feats[f\"zscore_{w}\"] = _safe_div((close - sma).to_numpy(), std.to_numpy())\n",
    "        feats[f\"dist_to_sma_{w}\"] = _safe_div((close - sma).to_numpy(), sma.to_numpy())\n",
    "\n",
    "    # RSI\n",
    "    for w in rsi_windows:\n",
    "        feats[f\"rsi_{w}\"] = _rsi(close, w)\n",
    "\n",
    "    # Bollinger features\n",
    "    for w in bb_windows:\n",
    "        mid = close.rolling(w, min_periods=w).mean()\n",
    "        sd = close.rolling(w, min_periods=w).std()\n",
    "        upper = mid + bb_k * sd\n",
    "        lower = mid - bb_k * sd\n",
    "        feats[f\"bb_pctb_{w}\"] = _safe_div((close - lower).to_numpy(), (upper - lower).to_numpy())\n",
    "        feats[f\"bb_bw_{w}\"] = _safe_div((upper - lower).to_numpy(), mid.to_numpy())\n",
    "\n",
    "    # MACD variants\n",
    "    for (f, s, sig) in [(12,26,9), (5,35,5), (8,17,9)]:\n",
    "        macd, sigl, hist = _macd(close, f, s, sig)\n",
    "        feats[f\"macd_{f}_{s}_{sig}\"] = macd\n",
    "        feats[f\"macd_signal_{f}_{s}_{sig}\"] = sigl\n",
    "        feats[f\"macd_hist_{f}_{s}_{sig}\"] = hist\n",
    "\n",
    "    # EWM volatility on log returns\n",
    "    for w in ewm_vol_windows:\n",
    "        feats[f\"ewm_vol_{w}\"] = ret1.ewm(span=w, adjust=False, min_periods=w).std()\n",
    "\n",
    "    # Rolling skew/kurt of log returns\n",
    "    for w in skew_kurt_windows:\n",
    "        feats[f\"skew_ret_{w}\"] = ret1.rolling(w, min_periods=w).skew()\n",
    "        feats[f\"kurt_ret_{w}\"] = ret1.rolling(w, min_periods=w).kurt()\n",
    "\n",
    "    # Rolling autocorr of returns (multiple windows × lags)\n",
    "    for w in acf_windows:\n",
    "        for L in acf_lags:\n",
    "            feats[f\"autocorr_ret_w{w}_lag{L}\"] = ret1.rolling(w, min_periods=w).corr(ret1.shift(L))\n",
    "\n",
    "    # Position within rolling range (0..1) and percentile ranks\n",
    "    for w in pos_range_windows:\n",
    "        feats[f\"pos_in_range_{w}\"] = _rolling_pos_in_range(close, w)\n",
    "        feats[f\"pctrank_{w}\"] = close.rolling(w, min_periods=w).apply(_rolling_percentile_rank, raw=True)\n",
    "\n",
    "    # Drawdowns (current & min-in-window)\n",
    "    cum_max = close.cummax()\n",
    "    curr_dd = (close / cum_max) - 1.0\n",
    "    feats[\"drawdown_curr\"] = curr_dd\n",
    "    for w in dd_windows:\n",
    "        wmax = close.rolling(w, min_periods=w).max()\n",
    "        wdd = (close / wmax) - 1.0\n",
    "        feats[f\"drawdown_curr_{w}\"] = wdd\n",
    "        # worst drawdown observed inside each rolling window\n",
    "        # compute rolling max drawdown via rolling of (close/rolling_max -1) min\n",
    "        feats[f\"drawdown_min_{w}\"] = wdd.rolling(w, min_periods=w).min()\n",
    "\n",
    "    # Time since rolling high/low\n",
    "    for w in dd_windows:\n",
    "        # positions within window: 0..w-1, we convert to \"age\"\n",
    "        pos_max = close.rolling(w, min_periods=w).apply(np.argmax, raw=True)\n",
    "        pos_min = close.rolling(w, min_periods=w).apply(np.argmin, raw=True)\n",
    "        feats[f\"days_since_high_{w}\"] = (w - 1) - pos_max\n",
    "        feats[f\"days_since_low_{w}\"]  = (w - 1) - pos_min\n",
    "\n",
    "    # DEMA / TEMA\n",
    "    for w in dema_tema_windows:\n",
    "        dema = _dema(close, w)\n",
    "        tema = _tema(close, w)\n",
    "        feats[f\"dema_{w}\"] = dema\n",
    "        feats[f\"tema_{w}\"] = tema\n",
    "        feats[f\"dist_to_dema_{w}\"] = _safe_div((close - dema).to_numpy(), dema.to_numpy())\n",
    "        feats[f\"dist_to_tema_{w}\"] = _safe_div((close - tema).to_numpy(), tema.to_numpy())\n",
    "\n",
    "    # Rolling Sharpe (mean/std of log returns)\n",
    "    for w in sharpe_windows:\n",
    "        mu = ret1.rolling(w, min_periods=w).mean()\n",
    "        sd = ret1.rolling(w, min_periods=w).std()\n",
    "        feats[f\"sharpe_{w}\"] = _safe_div((mu * np.sqrt(252)).to_numpy(), sd.to_numpy())\n",
    "\n",
    "    # ---------- Macro features ----------\n",
    "    if macro is not None and len(macro.columns) > 0:\n",
    "        macro = macro.copy()\n",
    "        macro.index = pd.to_datetime(macro.index)\n",
    "        macro = macro.sort_index().reindex(idx)  # align to close index\n",
    "\n",
    "        # Ensure float\n",
    "        for col in macro.columns:\n",
    "            macro[col] = pd.to_numeric(macro[col], errors=\"coerce\")\n",
    "\n",
    "        # Macro returns\n",
    "        mret = np.log(macro).diff()\n",
    "\n",
    "        for col in macro.columns:\n",
    "            # basic levels & lags\n",
    "            feats[f\"{col}_level\"] = macro[col]\n",
    "            for L in macro_lags:\n",
    "                feats[f\"{col}_ret_lag{L}\"] = mret[col].shift(L)\n",
    "\n",
    "            # rolling stats & correlations/betas with the asset's returns\n",
    "            for w in macro_windows:\n",
    "                feats[f\"{col}_vol_{w}\"] = mret[col].rolling(w, min_periods=w).std()\n",
    "                corr = ret1.rolling(w, min_periods=w).corr(mret[col])\n",
    "                cov  = ret1.rolling(w, min_periods=w).cov(mret[col])\n",
    "                varm = mret[col].rolling(w, min_periods=w).var()\n",
    "                beta = pd.Series(_safe_div(cov.to_numpy(), varm.to_numpy()), index=idx)\n",
    "                feats[f\"corr_{col}_{w}\"] = corr\n",
    "                feats[f\"beta_{col}_{w}\"] = beta\n",
    "                feats[f\"r2_{col}_{w}\"] = corr**2  # simple proxy\n",
    "\n",
    "            # simple cross terms (contemporaneous and lagged influence)\n",
    "            for L in (0, 1, 5):\n",
    "                feats[f\"ret_x_{col}_ret_lag{L}\"] = ret1 * mret[col].shift(L)\n",
    "\n",
    "    # Final cleaning\n",
    "    feats = feats.replace([np.inf, -np.inf], np.nan)\n",
    "    if dropna:\n",
    "        feats = feats.dropna()\n",
    "\n",
    "    return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BACKTESTING FUNCTION\n",
    "def backtest_1day_leverage(close_prices, signals, leverage=5.0, dates=None, apply_next_day=False):\n",
    "    \"\"\"\n",
    "    close_prices : np.ndarray shape (T,)\n",
    "    signals      : list or np.ndarray shape (T,) with values in {-1,0,1}\n",
    "                   +1 = buy, -1 = sell, 0 = flat\n",
    "    leverage     : float, e.g., 5.0 for 5x long/short\n",
    "    dates        : optional sequence of datetime-like (len T). If provided, returns a DataFrame.\n",
    "    apply_next_day : if True, use signal[t] on return[t+1] (no look-ahead for EOD signals)\n",
    "                     if False, use signal[t] on return[t] (intraday/same-day signal)\n",
    "    Returns:\n",
    "        If dates is None: dict of NumPy arrays\n",
    "        Else            : Pandas DataFrame indexed by dates\n",
    "    \"\"\"\n",
    "    cp = np.asarray(close_prices, dtype=float).reshape(-1)\n",
    "    sig = np.asarray(signals, dtype=float).reshape(-1)\n",
    "\n",
    "    if cp.ndim != 1 or sig.ndim != 1:\n",
    "        raise ValueError(\"close_prices and signals must be 1-D.\")\n",
    "    if cp.shape[0] != sig.shape[0]:\n",
    "        raise ValueError(f\"Length mismatch: prices={cp.shape[0]}, signals={sig.shape[0]}\")\n",
    "\n",
    "    T = cp.shape[0]\n",
    "\n",
    "    # daily % change; first element is NaN (no prior close)\n",
    "    daily_ret = np.empty(T, dtype=float)\n",
    "    daily_ret[0] = np.nan\n",
    "    daily_ret[1:] = (cp[1:] - cp[:-1]) / cp[:-1]\n",
    "\n",
    "    # apply signal with optional next-day shift\n",
    "    if apply_next_day:\n",
    "        # use today’s signal for tomorrow’s return\n",
    "        eff_sig = np.empty(T, dtype=float); eff_sig[:] = 0.0\n",
    "        eff_sig[1:] = sig[:-1]\n",
    "    else:\n",
    "        eff_sig = sig\n",
    "\n",
    "    # strategy return for each day (NaN day -> 0 return)\n",
    "    strat_ret = leverage * eff_sig * daily_ret\n",
    "    strat_ret[~np.isfinite(strat_ret)] = 0.0  # set NaN on day 0 to 0\n",
    "\n",
    "    # equity curve (start at 1.0)\n",
    "    equity = np.empty(T, dtype=float)\n",
    "    equity[0] = 1.0\n",
    "    # (1 + r_t) cumulative product; handle potential tiny numerical issues\n",
    "    equity[1:] = np.cumprod(1.0 + strat_ret[1:]) * 1.0\n",
    "\n",
    "    # Pack results\n",
    "    if dates is None:\n",
    "        return {\n",
    "            \"close\": cp,\n",
    "            \"signal\": sig,\n",
    "            \"daily_ret\": daily_ret,\n",
    "            \"strat_ret\": strat_ret,\n",
    "            \"equity\": equity,\n",
    "        }\n",
    "    else:\n",
    "        idx = pd.to_datetime(pd.Index(dates))\n",
    "        out = pd.DataFrame({\n",
    "            \"close\": cp,\n",
    "            \"signal\": sig,\n",
    "            \"daily_ret\": daily_ret,\n",
    "            \"strat_ret\": strat_ret,\n",
    "            \"equity\": equity,\n",
    "        }, index=idx)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS FOR PLOTTING\n",
    "\n",
    "\n",
    "def plot_equity_price_signals(close_prices, equity, signals, dates=None, title=\"Strategy vs Asset\"):\n",
    "    cp = np.asarray(close_prices, dtype=float).reshape(-1)\n",
    "    eq = np.asarray(equity, dtype=float).reshape(-1)\n",
    "    sig = np.asarray(signals, dtype=int).reshape(-1)\n",
    "    if not (len(cp) == len(eq) == len(sig)):\n",
    "        raise ValueError(f\"Length mismatch: price={len(cp)}, equity={len(eq)}, signals={len(sig)}\")\n",
    "\n",
    "    # Normalize price to start at 1.0\n",
    "    cp_norm = cp / cp[0]\n",
    "\n",
    "    # Handle dates\n",
    "    if dates is None:\n",
    "        x = np.arange(len(cp))\n",
    "        x_for_scatter = x\n",
    "        xlabel = \"Index\"\n",
    "    else:\n",
    "        idx = pd.to_datetime(pd.Index(dates))\n",
    "        x = idx\n",
    "        x_for_scatter = np.array(idx)\n",
    "        xlabel = \"Date\"\n",
    "\n",
    "    buys  = sig == 1\n",
    "    sells = sig == -1\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot normalized price\n",
    "    ax.plot(x, cp_norm, label=\"Price (normed)\", color=\"tab:blue\")\n",
    "    ax.scatter(x_for_scatter[buys],  cp_norm[buys],  marker=\"^\", s=40, label=\"Buy\", color=\"green\")\n",
    "    ax.scatter(x_for_scatter[sells], cp_norm[sells], marker=\"v\", s=40, label=\"Sell\", color=\"red\")\n",
    "\n",
    "    # Plot equity\n",
    "    ax.plot(x, eq, label=\"Equity\", color=\"tab:orange\")\n",
    "\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Normalized Value (start=1.0)\")\n",
    "    ax.legend(loc=\"best\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Convenience wrapper if you pass the backtest output directly\n",
    "def plot_from_backtest(bt):\n",
    "    \"\"\"\n",
    "    bt: dict returned by backtest_1day_leverage(...) OR a DataFrame with\n",
    "        columns ['close','equity','signal'] and a DatetimeIndex.\n",
    "    \"\"\"\n",
    "    if isinstance(bt, dict):\n",
    "        return plot_equity_price_signals(bt[\"close\"], bt[\"equity\"], bt[\"signal\"])\n",
    "    else:\n",
    "        return plot_equity_price_signals(\n",
    "            bt[\"close\"].to_numpy(),\n",
    "            bt[\"equity\"].to_numpy(),\n",
    "            bt[\"signal\"].to_numpy(),\n",
    "            dates=bt.index\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE METRICS FUNCTIONS\n",
    "\n",
    "def tangency_weights(returns,dropna=True,scale_cov=1):\n",
    "    if dropna:\n",
    "        returns = returns.dropna()\n",
    "\n",
    "    covmat_full = returns.cov()\n",
    "    covmat_diag = np.diag(np.diag(covmat_full))\n",
    "    covmat = scale_cov * covmat_full + (1-scale_cov) * covmat_diag\n",
    "\n",
    "    weights = np.linalg.solve(covmat,returns.mean())\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    return pd.DataFrame(weights, index=returns.columns,columns=['tangency weights'])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def performanceMetrics(returns,annualization=1, quantile=.05):\n",
    "    metrics = pd.DataFrame(index=returns.columns)\n",
    "    metrics['Mean'] = returns.mean() * annualization\n",
    "    metrics['Vol'] = returns.std() * np.sqrt(annualization)\n",
    "    metrics['Sharpe'] = (returns.mean() / returns.std()) * np.sqrt(annualization)\n",
    "\n",
    "    metrics['Min'] = returns.min()\n",
    "    metrics['Max'] = returns.max()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def display_correlation(df,list_maxmin=True):\n",
    "    \n",
    "    corrmat = df.corr()\n",
    "    #ignore self-correlation\n",
    "    corrmat[corrmat==1] = None\n",
    "    sns.heatmap(corrmat)\n",
    "\n",
    "    if list_maxmin:\n",
    "        corr_rank = corrmat.unstack().sort_values().dropna()\n",
    "        pair_max = corr_rank.index[-1]\n",
    "        pair_min = corr_rank.index[0]\n",
    "\n",
    "        print(f'MIN Correlation pair is {pair_min}')\n",
    "        print(f'MAX Correlation pair is {pair_max}')\n",
    "        \n",
    "    return\n",
    "\n",
    "        \n",
    "        \n",
    "def maximumDrawdown(returns):\n",
    "    cum_returns = (1 + returns).cumprod()\n",
    "    rolling_max = cum_returns.cummax()\n",
    "    drawdown = (cum_returns - rolling_max) / rolling_max\n",
    "\n",
    "    max_drawdown = drawdown.min()\n",
    "    end_date = drawdown.idxmin()\n",
    "    summary = pd.DataFrame({'Max Drawdown': max_drawdown, 'Bottom': end_date})\n",
    "\n",
    "    for col in drawdown:\n",
    "        summary.loc[col,'Peak'] = (rolling_max.loc[:end_date[col],col]).idxmax()\n",
    "        recovery = (drawdown.loc[end_date[col]:,col])\n",
    "        try:\n",
    "            summary.loc[col,'Recover'] = pd.to_datetime(recovery[recovery >= 0].index[0])\n",
    "        except:\n",
    "            summary.loc[col,'Recover'] = pd.to_datetime(None)\n",
    "\n",
    "        summary['Peak'] = pd.to_datetime(summary['Peak'])\n",
    "        try:\n",
    "            summary['Duration (to Recover)'] = (summary['Recover'] - summary['Peak'])\n",
    "        except:\n",
    "            summary['Duration (to Recover)'] = None\n",
    "            \n",
    "        summary = summary[['Max Drawdown','Peak','Bottom','Recover','Duration (to Recover)']]\n",
    "\n",
    "    return summary    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tailMetrics(returns, quantile=.05, relative=False, mdd=True):\n",
    "    metrics = pd.DataFrame(index=returns.columns)\n",
    "    metrics['Skewness'] = returns.skew()\n",
    "    metrics['Kurtosis'] = returns.kurtosis()\n",
    "\n",
    "    VaR = returns.quantile(quantile)\n",
    "    CVaR = (returns[returns < returns.quantile(quantile)]).mean()\n",
    "\n",
    "    if relative:\n",
    "        VaR = (VaR - returns.mean())/returns.std()\n",
    "        CVaR = (CVaR - returns.mean())/returns.std()\n",
    "\n",
    "    metrics[f'VaR ({quantile})'] = VaR\n",
    "    metrics[f'CVaR ({quantile})'] = CVaR\n",
    "\n",
    "    if mdd:\n",
    "        mdd_stats = maximumDrawdown(returns)\n",
    "        metrics = metrics.join(mdd_stats)\n",
    "\n",
    "        if relative:\n",
    "            metrics['Max Drawdown'] = (metrics['Max Drawdown'] - returns.mean())/returns.std()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_ols_metrics(regressors, targets, annualization=1, ignorenan=True):\n",
    "    # ensure regressors and targets are pandas dataframes, as expected\n",
    "    if not isinstance(regressors, pd.DataFrame):\n",
    "        regressors = regressors.to_frame()\n",
    "    if not isinstance(targets, pd.DataFrame):\n",
    "        targets = targets.to_frame()\n",
    "\n",
    "    # align the targets and regressors on the same dates\n",
    "    df_aligned = targets.join(regressors, how='inner', lsuffix='y ')\n",
    "    Y = df_aligned[targets.columns]\n",
    "    Xset = df_aligned[regressors.columns]\n",
    "\n",
    "    reg = pd.DataFrame(index=targets.columns)\n",
    "    for col in Y.columns:\n",
    "        y = Y[col]\n",
    "        \n",
    "        if ignorenan:\n",
    "            # ensure we use only non-NaN dates\n",
    "            alldata = Xset.join(y,lsuffix='X')\n",
    "            mask = alldata.notnull().all(axis=1)\n",
    "            y = y[mask]\n",
    "            X = Xset[mask]\n",
    "        else:\n",
    "            X = Xset\n",
    "\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        reg.loc[col, 'alpha'] = model.intercept_ * annualization\n",
    "        reg.loc[col, regressors.columns] = model.coef_\n",
    "        reg.loc[col, 'r-squared'] = model.score(X, y)\n",
    "\n",
    "        # sklearn does not return the residuals, so we need to build them\n",
    "        yfit = model.predict(X)\n",
    "        residuals = y - yfit\n",
    "\n",
    "        num_roundoff = 1e-12\n",
    "        \n",
    "        # Treynor Ratio is only defined for univariate regression\n",
    "        if Xset.shape[1] == 1:\n",
    "            if np.abs(model.coef_) < num_roundoff:\n",
    "                reg.loc[col,'Treynor Ratio'] = None\n",
    "            else:\n",
    "                reg.loc[col,'Treynor Ratio'] = (y.mean() / model.coef_) * annualization\n",
    "\n",
    "        \n",
    "        # if intercept =0, numerical roundoff will nonetheless show nonzero Info Ratio        \n",
    "        if np.abs(model.intercept_) < num_roundoff:\n",
    "            reg.loc[col, 'Info Ratio'] = None\n",
    "        else:\n",
    "            reg.loc[col, 'Info Ratio'] = (model.intercept_ / residuals.std()) * np.sqrt(annualization)\n",
    "\n",
    "    return reg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def penalized_reg_limit_gross(func, X, y, limit=2, penalty=1e-6, fit_intercept=True):\n",
    "    wts = np.ones(X.shape[1]) * 100\n",
    "    \n",
    "    while np.abs(wts).sum()>limit:\n",
    "        penalty *= 1.1\n",
    "        model = func(alpha=penalty, fit_intercept=fit_intercept).fit(X,y)\n",
    "        wts = model.coef_ / model.coef_.sum()\n",
    "    \n",
    "    return wts, penalty\n",
    "\n",
    "\n",
    "\n",
    "def penalized_reg_limit_X(func, X, y, limit=10, penalty=1e-6, fit_intercept=True):\n",
    "    wts = np.ones(X.shape[1]) * 100\n",
    "    \n",
    "    Nx = np.inf\n",
    "    while Nx>limit:\n",
    "        penalty *= 1.1\n",
    "        model = func(alpha=penalty, fit_intercept=fit_intercept).fit(X,y)\n",
    "        wts = model.coef_ / model.coef_.sum()\n",
    "    \n",
    "        if func is Lasso:\n",
    "            Nx = (np.abs(wts)>1e-4).sum()            \n",
    "        else:\n",
    "            Nx = 0\n",
    "            \n",
    "    return wts, penalty\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "def cluster_corr(corr_array, inplace=False):\n",
    "    \"\"\"\n",
    "    Rearranges the correlation matrix, corr_array, so that groups of highly \n",
    "    correlated variables are next to eachother \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    corr_array : pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame or numpy.ndarray\n",
    "        a NxN correlation matrix with the columns and rows rearranged\n",
    "    \"\"\"\n",
    "    pairwise_distances = sch.distance.pdist(corr_array)\n",
    "    linkage = sch.linkage(pairwise_distances, method='complete')\n",
    "    cluster_distance_threshold = pairwise_distances.max()/2\n",
    "    idx_to_cluster_array = sch.fcluster(linkage, cluster_distance_threshold, \n",
    "                                        criterion='distance')\n",
    "    idx = np.argsort(idx_to_cluster_array)\n",
    "    \n",
    "    if not inplace:\n",
    "        corr_array = corr_array.copy()\n",
    "    \n",
    "    if isinstance(corr_array, pd.DataFrame):\n",
    "        return corr_array.iloc[idx, :].T.iloc[idx, :]\n",
    "    return corr_array[idx, :][:, idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "CORE TRADING CLASS \n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import logging\n",
    "from typing import Optional, Dict, List, Union\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CoreTradingSystem:\n",
    "    \"\"\"\n",
    "    Core trading system that integrates:\n",
    "    - Alpaca API for live trading\n",
    "    - yfinance for historical data\n",
    "    - Technical indicators\n",
    "    - Backtesting capabilities\n",
    "    - Performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 alpaca_api_key: str,\n",
    "                 alpaca_secret_key: str,\n",
    "                 alpaca_base_url: str = \"https://paper-api.alpaca.markets\",\n",
    "                 default_lookback_days: int = 2520):  # ~10 years\n",
    "        \n",
    "        # Initialize Alpaca API\n",
    "        self.api = tradeapi.REST(\n",
    "            alpaca_api_key,\n",
    "            alpaca_secret_key,\n",
    "            alpaca_base_url,\n",
    "            api_version='v2'\n",
    "        )\n",
    "        \n",
    "        # Trading parameters\n",
    "        self.default_lookback = default_lookback_days\n",
    "        self.positions = {}\n",
    "        self.signals_history = {}\n",
    "        self.performance_data = {}\n",
    "        \n",
    "        # Set up logging\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Test connection\n",
    "        try:\n",
    "            account = self.api.get_account()\n",
    "            self.logger.info(f\"Connected to Alpaca - Account Status: {account.status}\")\n",
    "            self.logger.info(f\"Buying Power: ${account.buying_power}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to connect to Alpaca: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_historical_data(self, symbol: str, lookback_days: Optional[int] = None) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Get historical price data using yfinance\n",
    "        Returns close prices as pandas Series\n",
    "        \"\"\"\n",
    "        if lookback_days is None:\n",
    "            lookback_days = self.default_lookback\n",
    "            \n",
    "        try:\n",
    "            # Calculate date range\n",
    "            end_date = datetime.now()\n",
    "            start_date = end_date - timedelta(days=lookback_days)\n",
    "            \n",
    "            # Fetch data using yfinance\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            hist_data = ticker.history(start=start_date, end=end_date)\n",
    "            \n",
    "            if hist_data.empty:\n",
    "                raise ValueError(f\"No data found for symbol {symbol}\")\n",
    "            \n",
    "            # Return close prices\n",
    "            close_prices = hist_data['Close']\n",
    "            close_prices.name = 'close'\n",
    "            \n",
    "            self.logger.info(f\"Retrieved {len(close_prices)} days of data for {symbol}\")\n",
    "            return close_prices\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error fetching data for {symbol}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def create_features(self, symbol: str, macro_data: Optional[pd.DataFrame] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create technical indicators for a given symbol\n",
    "        Uses your build_tech_indicators function\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get historical data\n",
    "            close_prices = self.get_historical_data(symbol)\n",
    "            \n",
    "            # Create technical indicators using your existing function\n",
    "            # Note: Using your original function names with asterisks - you'll need to fix these\n",
    "            features = self.build_tech_indicators(close_prices, macro=macro_data)\n",
    "            \n",
    "            self.logger.info(f\"Created {len(features.columns)} features for {symbol}\")\n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error creating features for {symbol}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def generate_signals(self, features: pd.DataFrame, model=None) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Generate trading signals from features\n",
    "        Override this method to implement your specific strategy\n",
    "        \n",
    "        Returns:\n",
    "            pd.Series with values in {-1, 0, 1}\n",
    "            -1 = sell/short, 0 = hold/flat, 1 = buy/long\n",
    "        \"\"\"\n",
    "        # Placeholder strategy - implement your ML model here\n",
    "        # This is a simple momentum example\n",
    "        \n",
    "        if 'ret_1' in features.columns:\n",
    "            # Simple momentum strategy based on 1-day return\n",
    "            signals = pd.Series(0, index=features.index)\n",
    "            \n",
    "            # Buy if positive momentum, sell if negative\n",
    "            momentum = features['ret_1'].rolling(5).mean()\n",
    "            signals[momentum > 0.001] = 1   # Buy signal\n",
    "            signals[momentum < -0.001] = -1  # Sell signal\n",
    "            \n",
    "            return signals\n",
    "        else:\n",
    "            # Return neutral signals if no momentum data\n",
    "            return pd.Series(0, index=features.index)\n",
    "    \n",
    "    def backtest_strategy(self, symbol: str, leverage: float = 1.0, \n",
    "                         start_date: Optional[str] = None, \n",
    "                         end_date: Optional[str] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Backtest the strategy for a given symbol\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create features\n",
    "            features = self.create_features(symbol)\n",
    "            \n",
    "            # Generate signals\n",
    "            signals = self.generate_signals(features)\n",
    "            \n",
    "            # Filter by date range if specified\n",
    "            if start_date or end_date:\n",
    "                mask = pd.Series(True, index=signals.index)\n",
    "                if start_date:\n",
    "                    mask = mask & (signals.index >= pd.to_datetime(start_date))\n",
    "                if end_date:\n",
    "                    mask = mask & (signals.index <= pd.to_datetime(end_date))\n",
    "                \n",
    "                signals = signals[mask]\n",
    "                # Get corresponding close prices\n",
    "                close_prices = self.get_historical_data(symbol)\n",
    "                close_prices = close_prices[mask]\n",
    "            else:\n",
    "                close_prices = self.get_historical_data(symbol)\n",
    "                # Align signals and prices\n",
    "                common_dates = signals.index.intersection(close_prices.index)\n",
    "                signals = signals[common_dates]\n",
    "                close_prices = close_prices[common_dates]\n",
    "            \n",
    "            # Run backtest using your existing function\n",
    "            backtest_results = self.backtest_1day_leverage(\n",
    "                close_prices=close_prices.values,\n",
    "                signals=signals.values,\n",
    "                leverage=leverage,\n",
    "                dates=signals.index,\n",
    "                apply_next_day=True  # Avoid look-ahead bias\n",
    "            )\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            returns = backtest_results['strat_ret']\n",
    "            returns_series = pd.Series(returns, index=backtest_results.index)\n",
    "            \n",
    "            # Store results\n",
    "            self.performance_data[symbol] = {\n",
    "                'backtest': backtest_results,\n",
    "                'returns': returns_series,\n",
    "                'signals': signals,\n",
    "                'leverage': leverage\n",
    "            }\n",
    "            \n",
    "            self.logger.info(f\"Backtesting completed for {symbol}\")\n",
    "            return backtest_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error backtesting {symbol}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def get_current_position(self, symbol: str) -> float:\n",
    "        \"\"\"Get current position size for a symbol\"\"\"\n",
    "        try:\n",
    "            position = self.api.get_position(symbol)\n",
    "            return float(position.qty)\n",
    "        except:\n",
    "            # No position found\n",
    "            return 0.0\n",
    "    \n",
    "    def place_order(self, symbol: str, qty: float, side: str = 'buy') -> bool:\n",
    "        \"\"\"\n",
    "        Place an order with Alpaca\n",
    "        \n",
    "        Args:\n",
    "            symbol: Stock symbol\n",
    "            qty: Quantity (positive number)\n",
    "            side: 'buy' or 'sell'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if qty == 0:\n",
    "                self.logger.info(f\"No order placed for {symbol} - zero quantity\")\n",
    "                return True\n",
    "            \n",
    "            order = self.api.submit_order(\n",
    "                symbol=symbol,\n",
    "                qty=abs(qty),\n",
    "                side=side,\n",
    "                type='market',\n",
    "                time_in_force='day'\n",
    "            )\n",
    "            \n",
    "            self.logger.info(f\"Order placed: {side} {qty} shares of {symbol}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error placing order for {symbol}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def execute_signal(self, symbol: str, signal: int, position_size: float = 1000) -> bool:\n",
    "        \"\"\"\n",
    "        Execute a trading signal\n",
    "        \n",
    "        Args:\n",
    "            symbol: Stock symbol\n",
    "            signal: -1 (sell/short), 0 (hold), 1 (buy/long)\n",
    "            position_size: Dollar amount to trade\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get current price and position\n",
    "            current_price = self.get_historical_data(symbol, lookback_days=2).iloc[-1]\n",
    "            current_position = self.get_current_position(symbol)\n",
    "            \n",
    "            # Calculate target position\n",
    "            if signal == 1:  # Buy signal\n",
    "                target_shares = position_size / current_price\n",
    "            elif signal == -1:  # Sell signal\n",
    "                target_shares = -position_size / current_price\n",
    "            else:  # Hold signal\n",
    "                target_shares = current_position\n",
    "            \n",
    "            # Calculate shares to trade\n",
    "            shares_to_trade = target_shares - current_position\n",
    "            \n",
    "            if abs(shares_to_trade) < 1:  # Less than 1 share\n",
    "                return True\n",
    "            \n",
    "            # Execute trade\n",
    "            if shares_to_trade > 0:\n",
    "                success = self.place_order(symbol, shares_to_trade, 'buy')\n",
    "            else:\n",
    "                success = self.place_order(symbol, abs(shares_to_trade), 'sell')\n",
    "            \n",
    "            if success:\n",
    "                self.positions[symbol] = target_shares\n",
    "                self.logger.info(f\"Signal executed: {symbol} signal={signal}, position={target_shares:.2f}\")\n",
    "            \n",
    "            return success\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error executing signal for {symbol}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def run_strategy(self, symbols: List[str], position_size: float = 1000, \n",
    "                    sleep_time: int = 3600) -> None:\n",
    "        \"\"\"\n",
    "        Run the trading strategy continuously\n",
    "        \n",
    "        Args:\n",
    "            symbols: List of symbols to trade\n",
    "            position_size: Dollar amount per position\n",
    "            sleep_time: Time to sleep between iterations (seconds)\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Starting strategy for symbols: {symbols}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # Check if market is open\n",
    "                clock = self.api.get_clock()\n",
    "                if not clock.is_open:\n",
    "                    self.logger.info(\"Market is closed, waiting...\")\n",
    "                    time.sleep(300)  # Sleep 5 minutes\n",
    "                    continue\n",
    "                \n",
    "                for symbol in symbols:\n",
    "                    try:\n",
    "                        # Create features\n",
    "                        features = self.create_features(symbol)\n",
    "                        \n",
    "                        # Generate signal for latest data point\n",
    "                        signals = self.generate_signals(features)\n",
    "                        latest_signal = signals.iloc[-1] if len(signals) > 0 else 0\n",
    "                        \n",
    "                        # Execute signal\n",
    "                        self.execute_signal(symbol, latest_signal, position_size)\n",
    "                        \n",
    "                        # Store signal\n",
    "                        if symbol not in self.signals_history:\n",
    "                            self.signals_history[symbol] = []\n",
    "                        self.signals_history[symbol].append({\n",
    "                            'timestamp': datetime.now(),\n",
    "                            'signal': latest_signal\n",
    "                        })\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        self.logger.error(f\"Error processing {symbol}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # Sleep until next iteration\n",
    "                self.logger.info(f\"Strategy iteration complete, sleeping {sleep_time} seconds\")\n",
    "                time.sleep(sleep_time)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                self.logger.info(\"Strategy interrupted by user\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Unexpected error in strategy loop: {e}\")\n",
    "                time.sleep(60)  # Sleep 1 minute on error\n",
    "    \n",
    "    def get_performance_summary(self, symbol: str) -> Dict:\n",
    "        \"\"\"Get performance summary for a symbol\"\"\"\n",
    "        if symbol not in self.performance_data:\n",
    "            self.logger.warning(f\"No performance data found for {symbol}\")\n",
    "            return {}\n",
    "        \n",
    "        data = self.performance_data[symbol]\n",
    "        returns = data['returns']\n",
    "        \n",
    "        # Calculate basic metrics\n",
    "        total_return = (data['backtest']['equity'].iloc[-1] - 1) * 100\n",
    "        sharpe_ratio = (returns.mean() / returns.std()) * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        max_drawdown = ((data['backtest']['equity'].cummax() - data['backtest']['equity']) / data['backtest']['equity'].cummax()).max() * 100\n",
    "        \n",
    "        return {\n",
    "            'symbol': symbol,\n",
    "            'total_return_pct': total_return,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown_pct': max_drawdown,\n",
    "            'num_trades': (data['signals'] != 0).sum(),\n",
    "            'win_rate': (returns[returns > 0]).count() / len(returns) * 100 if len(returns) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    # Include your existing functions (with original names)\n",
    "    # You'll need to copy these from your previous code parts\n",
    "    \n",
    "    def build_tech_indicators(self,\n",
    "        close: Union[pd.Series, pd.DataFrame],\n",
    "        macro: Optional[pd.DataFrame] = None,\n",
    "        *,\n",
    "        ma_windows: Sequence[int] = (\n",
    "            3,5,7,9,10,12,14,15,18,20,21,24,30,34,35,40,45,50,55,60,63,70,75,80,90,100,120,126,150,180,200,210,220,240,250,252\n",
    "        ),\n",
    "        roc_periods: Sequence[int] = (\n",
    "            1,2,3,4,5,7,9,10,12,14,15,20,21,30,35,40,45,50,60,63,90,120,126,150,180,200,252\n",
    "        ),\n",
    "        rsi_windows: Sequence[int] = (6,7,9,10,12,14,20,21,28),\n",
    "        bb_windows: Sequence[int] = (20,50,100),\n",
    "        bb_k: float = 2.0,\n",
    "        ewm_vol_windows: Sequence[int] = (10,20,21,30,50,63),\n",
    "        acf_windows: Sequence[int] = (21,63,126),\n",
    "        acf_lags: Sequence[int] = (1,2,3,4,5),\n",
    "        skew_kurt_windows: Sequence[int] = (21,63,126,252),\n",
    "        dd_windows: Sequence[int] = (21,63,126,252),\n",
    "        pos_range_windows: Sequence[int] = (10,20,50,100,252),\n",
    "        dema_tema_windows: Sequence[int] = (10,12,14,20,21,30,35,50,63,100),\n",
    "        sharpe_windows: Sequence[int] = (21,63,126,252),\n",
    "        macro_lags: Sequence[int] = (1,5,10),\n",
    "        macro_windows: Sequence[int] = (5,21,63,126,252),\n",
    "        dropna: bool = True\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Build a wide feature matrix of technical indicators from close prices and optional macro series.\n",
    "        Parameters\n",
    "        ----------\n",
    "        close : pd.Series or DataFrame\n",
    "            Close prices (datetime index). If DataFrame, must include 'Close' or have 1 column.\n",
    "        macro : pd.DataFrame, optional\n",
    "            Exogenous series (e.g., VIX). Columns = variables, datetime index. Aligned to 'close'.\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Time-indexed feature DataFrame.\n",
    "        \"\"\"\n",
    "        close = _ensure_series(close, name=\"close\")\n",
    "        idx = close.index\n",
    "        feats = pd.DataFrame(index=idx)\n",
    "\n",
    "        # Basic transforms\n",
    "        logp = np.log(close)\n",
    "        ret1 = logp.diff()                   # log return t/t-1\n",
    "        feats[\"ret_1\"] = ret1\n",
    "\n",
    "        # Multi-horizon ROC (simple returns) and log returns\n",
    "        for p in roc_periods:\n",
    "            feats[f\"roc_{p}\"] = close.pct_change(p)\n",
    "            feats[f\"logret_{p}\"] = logp.diff(p)\n",
    "\n",
    "        # Moving averages, EMA, rolling std, z-score, distance-to-MA\n",
    "        for w in ma_windows:\n",
    "            sma = close.rolling(w, min_periods=w).mean()\n",
    "            ema = close.ewm(span=w, adjust=False, min_periods=w).mean()\n",
    "            std = close.rolling(w, min_periods=w).std()\n",
    "            feats[f\"sma_{w}\"] = sma\n",
    "            feats[f\"ema_{w}\"] = ema\n",
    "            feats[f\"std_{w}\"] = std\n",
    "            feats[f\"zscore_{w}\"] = _safe_div((close - sma).to_numpy(), std.to_numpy())\n",
    "            feats[f\"dist_to_sma_{w}\"] = _safe_div((close - sma).to_numpy(), sma.to_numpy())\n",
    "\n",
    "        # RSI\n",
    "        for w in rsi_windows:\n",
    "            feats[f\"rsi_{w}\"] = _rsi(close, w)\n",
    "\n",
    "        # Bollinger features\n",
    "        for w in bb_windows:\n",
    "            mid = close.rolling(w, min_periods=w).mean()\n",
    "            sd = close.rolling(w, min_periods=w).std()\n",
    "            upper = mid + bb_k * sd\n",
    "            lower = mid - bb_k * sd\n",
    "            feats[f\"bb_pctb_{w}\"] = _safe_div((close - lower).to_numpy(), (upper - lower).to_numpy())\n",
    "            feats[f\"bb_bw_{w}\"] = _safe_div((upper - lower).to_numpy(), mid.to_numpy())\n",
    "\n",
    "        # MACD variants\n",
    "        for (f, s, sig) in [(12,26,9), (5,35,5), (8,17,9)]:\n",
    "            macd, sigl, hist = _macd(close, f, s, sig)\n",
    "            feats[f\"macd_{f}_{s}_{sig}\"] = macd\n",
    "            feats[f\"macd_signal_{f}_{s}_{sig}\"] = sigl\n",
    "            feats[f\"macd_hist_{f}_{s}_{sig}\"] = hist\n",
    "\n",
    "        # EWM volatility on log returns\n",
    "        for w in ewm_vol_windows:\n",
    "            feats[f\"ewm_vol_{w}\"] = ret1.ewm(span=w, adjust=False, min_periods=w).std()\n",
    "\n",
    "        # Rolling skew/kurt of log returns\n",
    "        for w in skew_kurt_windows:\n",
    "            feats[f\"skew_ret_{w}\"] = ret1.rolling(w, min_periods=w).skew()\n",
    "            feats[f\"kurt_ret_{w}\"] = ret1.rolling(w, min_periods=w).kurt()\n",
    "\n",
    "        # Rolling autocorr of returns (multiple windows × lags)\n",
    "        for w in acf_windows:\n",
    "            for L in acf_lags:\n",
    "                feats[f\"autocorr_ret_w{w}_lag{L}\"] = ret1.rolling(w, min_periods=w).corr(ret1.shift(L))\n",
    "\n",
    "        # Position within rolling range (0..1) and percentile ranks\n",
    "        for w in pos_range_windows:\n",
    "            feats[f\"pos_in_range_{w}\"] = _rolling_pos_in_range(close, w)\n",
    "            feats[f\"pctrank_{w}\"] = close.rolling(w, min_periods=w).apply(_rolling_percentile_rank, raw=True)\n",
    "\n",
    "        # Drawdowns (current & min-in-window)\n",
    "        cum_max = close.cummax()\n",
    "        curr_dd = (close / cum_max) - 1.0\n",
    "        feats[\"drawdown_curr\"] = curr_dd\n",
    "        for w in dd_windows:\n",
    "            wmax = close.rolling(w, min_periods=w).max()\n",
    "            wdd = (close / wmax) - 1.0\n",
    "            feats[f\"drawdown_curr_{w}\"] = wdd\n",
    "            # worst drawdown observed inside each rolling window\n",
    "            # compute rolling max drawdown via rolling of (close/rolling_max -1) min\n",
    "            feats[f\"drawdown_min_{w}\"] = wdd.rolling(w, min_periods=w).min()\n",
    "\n",
    "        # Time since rolling high/low\n",
    "        for w in dd_windows:\n",
    "            # positions within window: 0..w-1, we convert to \"age\"\n",
    "            pos_max = close.rolling(w, min_periods=w).apply(np.argmax, raw=True)\n",
    "            pos_min = close.rolling(w, min_periods=w).apply(np.argmin, raw=True)\n",
    "            feats[f\"days_since_high_{w}\"] = (w - 1) - pos_max\n",
    "            feats[f\"days_since_low_{w}\"]  = (w - 1) - pos_min\n",
    "\n",
    "        # DEMA / TEMA\n",
    "        for w in dema_tema_windows:\n",
    "            dema = _dema(close, w)\n",
    "            tema = _tema(close, w)\n",
    "            feats[f\"dema_{w}\"] = dema\n",
    "            feats[f\"tema_{w}\"] = tema\n",
    "            feats[f\"dist_to_dema_{w}\"] = _safe_div((close - dema).to_numpy(), dema.to_numpy())\n",
    "            feats[f\"dist_to_tema_{w}\"] = _safe_div((close - tema).to_numpy(), tema.to_numpy())\n",
    "\n",
    "        # Rolling Sharpe (mean/std of log returns)\n",
    "        for w in sharpe_windows:\n",
    "            mu = ret1.rolling(w, min_periods=w).mean()\n",
    "            sd = ret1.rolling(w, min_periods=w).std()\n",
    "            feats[f\"sharpe_{w}\"] = _safe_div((mu * np.sqrt(252)).to_numpy(), sd.to_numpy())\n",
    "\n",
    "        # ---------- Macro features ----------\n",
    "        if macro is not None and len(macro.columns) > 0:\n",
    "            macro = macro.copy()\n",
    "            macro.index = pd.to_datetime(macro.index)\n",
    "            macro = macro.sort_index().reindex(idx)  # align to close index\n",
    "\n",
    "            # Ensure float\n",
    "            for col in macro.columns:\n",
    "                macro[col] = pd.to_numeric(macro[col], errors=\"coerce\")\n",
    "\n",
    "            # Macro returns\n",
    "            mret = np.log(macro).diff()\n",
    "\n",
    "            for col in macro.columns:\n",
    "                # basic levels & lags\n",
    "                feats[f\"{col}_level\"] = macro[col]\n",
    "                for L in macro_lags:\n",
    "                    feats[f\"{col}_ret_lag{L}\"] = mret[col].shift(L)\n",
    "\n",
    "                # rolling stats & correlations/betas with the asset's returns\n",
    "                for w in macro_windows:\n",
    "                    feats[f\"{col}_vol_{w}\"] = mret[col].rolling(w, min_periods=w).std()\n",
    "                    corr = ret1.rolling(w, min_periods=w).corr(mret[col])\n",
    "                    cov  = ret1.rolling(w, min_periods=w).cov(mret[col])\n",
    "                    varm = mret[col].rolling(w, min_periods=w).var()\n",
    "                    beta = pd.Series(_safe_div(cov.to_numpy(), varm.to_numpy()), index=idx)\n",
    "                    feats[f\"corr_{col}_{w}\"] = corr\n",
    "                    feats[f\"beta_{col}_{w}\"] = beta\n",
    "                    feats[f\"r2_{col}_{w}\"] = corr**2  # simple proxy\n",
    "\n",
    "                # simple cross terms (contemporaneous and lagged influence)\n",
    "                for L in (0, 1, 5):\n",
    "                    feats[f\"ret_x_{col}_ret_lag{L}\"] = ret1 * mret[col].shift(L)\n",
    "\n",
    "        # Final cleaning\n",
    "        feats = feats.replace([np.inf, -np.inf], np.nan)\n",
    "        if dropna:\n",
    "            feats = feats.dropna()\n",
    "\n",
    "        return feats\n",
    "\n",
    "    \n",
    "    def backtest_1day_leverage(self, close_prices, signals, leverage=5.0, dates=None, apply_next_day=False):\n",
    "        \"\"\"\n",
    "        close_prices : np.ndarray shape (T,)\n",
    "        signals      : list or np.ndarray shape (T,) with values in {-1,0,1}\n",
    "                    +1 = buy, -1 = sell, 0 = flat\n",
    "        leverage     : float, e.g., 5.0 for 5x long/short\n",
    "        dates        : optional sequence of datetime-like (len T). If provided, returns a DataFrame.\n",
    "        apply_next_day : if True, use signal[t] on return[t+1] (no look-ahead for EOD signals)\n",
    "                        if False, use signal[t] on return[t] (intraday/same-day signal)\n",
    "        Returns:\n",
    "            If dates is None: dict of NumPy arrays\n",
    "            Else            : Pandas DataFrame indexed by dates\n",
    "        \"\"\"\n",
    "        cp = np.asarray(close_prices, dtype=float).reshape(-1)\n",
    "        sig = np.asarray(signals, dtype=float).reshape(-1)\n",
    "\n",
    "        if cp.ndim != 1 or sig.ndim != 1:\n",
    "            raise ValueError(\"close_prices and signals must be 1-D.\")\n",
    "        if cp.shape[0] != sig.shape[0]:\n",
    "            raise ValueError(f\"Length mismatch: prices={cp.shape[0]}, signals={sig.shape[0]}\")\n",
    "\n",
    "        T = cp.shape[0]\n",
    "\n",
    "        # daily % change; first element is NaN (no prior close)\n",
    "        daily_ret = np.empty(T, dtype=float)\n",
    "        daily_ret[0] = np.nan\n",
    "        daily_ret[1:] = (cp[1:] - cp[:-1]) / cp[:-1]\n",
    "\n",
    "        # apply signal with optional next-day shift\n",
    "        if apply_next_day:\n",
    "            # use today’s signal for tomorrow’s return\n",
    "            eff_sig = np.empty(T, dtype=float); eff_sig[:] = 0.0\n",
    "            eff_sig[1:] = sig[:-1]\n",
    "        else:\n",
    "            eff_sig = sig\n",
    "\n",
    "        # strategy return for each day (NaN day -> 0 return)\n",
    "        strat_ret = leverage * eff_sig * daily_ret\n",
    "        strat_ret[~np.isfinite(strat_ret)] = 0.0  # set NaN on day 0 to 0\n",
    "\n",
    "        # equity curve (start at 1.0)\n",
    "        equity = np.empty(T, dtype=float)\n",
    "        equity[0] = 1.0\n",
    "        # (1 + r_t) cumulative product; handle potential tiny numerical issues\n",
    "        equity[1:] = np.cumprod(1.0 + strat_ret[1:]) * 1.0\n",
    "\n",
    "        # Pack results\n",
    "        if dates is None:\n",
    "            return {\n",
    "                \"close\": cp,\n",
    "                \"signal\": sig,\n",
    "                \"daily_ret\": daily_ret,\n",
    "                \"strat_ret\": strat_ret,\n",
    "                \"equity\": equity,\n",
    "            }\n",
    "        else:\n",
    "            idx = pd.to_datetime(pd.Index(dates))\n",
    "            out = pd.DataFrame({\n",
    "                \"close\": cp,\n",
    "                \"signal\": sig,\n",
    "                \"daily_ret\": daily_ret,\n",
    "                \"strat_ret\": strat_ret,\n",
    "                \"equity\": equity,\n",
    "            }, index=idx)\n",
    "            return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trading_system():\n",
    "    \"\"\"Test the basic functionality of the trading system\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"TESTING CORE TRADING SYSTEM\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Test API Connection\n",
    "    print(\"\\n1. Testing Alpaca Connection...\")\n",
    "    try:\n",
    "        # You'll need to set these environment variables or replace with your keys\n",
    "        API_KEY = \"PKSRU8TI6JTHJG0KF87R\"  # Your paper trading key\n",
    "        SECRET_KEY = \"goumjgb1Ua9JZ5jpgF9iWiM07GJcCiXnwftYq8My\"  # Your paper trading secret\n",
    "        \n",
    "        trader = CoreTradingSystem(\n",
    "            alpaca_api_key=API_KEY,\n",
    "            alpaca_secret_key=SECRET_KEY,\n",
    "            alpaca_base_url=\"https://paper-api.alpaca.markets\"\n",
    "        )\n",
    "        print(\"✓ Alpaca connection successful!\")\n",
    "        \n",
    "        # Get account info\n",
    "        account = trader.api.get_account()\n",
    "        print(f\"✓ Account Status: {account.status}\")\n",
    "        print(f\"✓ Buying Power: ${float(account.buying_power):,.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Alpaca connection failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 2: Test Data Retrieval\n",
    "    print(\"\\n2. Testing Historical Data Retrieval...\")\n",
    "    try:\n",
    "        test_symbol = \"AAPL\"\n",
    "        close_prices = trader.get_historical_data(test_symbol, lookback_days=3650)\n",
    "        \n",
    "        print(f\"✓ Retrieved {len(close_prices)} days of data for {test_symbol}\")\n",
    "        print(f\"✓ Date range: {close_prices.index[0].date()} to {close_prices.index[-1].date()}\")\n",
    "        print(f\"✓ Latest price: ${close_prices.iloc[-1]:.2f}\")\n",
    "        print(f\"✓ Data type: {type(close_prices)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Data retrieval failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Test Basic Feature Creation (simplified)\n",
    "    print(\"\\n3. Testing Basic Feature Creation...\")\n",
    "    try:\n",
    "        # Simple features without your complex function\n",
    "        features = pd.DataFrame(index=close_prices.index)\n",
    "        \n",
    "        # Basic returns\n",
    "        features['ret_1'] = close_prices.pct_change()\n",
    "        features['ret_5'] = close_prices.pct_change(5)\n",
    "        \n",
    "        # Simple moving averages\n",
    "        features['sma_20'] = close_prices.rolling(20).mean()\n",
    "        features['sma_50'] = close_prices.rolling(50).mean()\n",
    "        \n",
    "        # RSI (simplified)\n",
    "        delta = close_prices.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "        rs = gain / loss\n",
    "        features['rsi_14'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Remove NaN rows\n",
    "        features = features.dropna()\n",
    "        \n",
    "        print(f\"✓ Created {len(features.columns)} basic features\")\n",
    "        print(f\"✓ Feature data shape: {features.shape}\")\n",
    "        print(f\"✓ Latest RSI: {features['rsi_14'].iloc[-1]:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Feature creation failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 4: Test Signal Generation\n",
    "    print(\"\\n4. Testing Signal Generation...\")\n",
    "    try:\n",
    "        # Simple momentum strategy\n",
    "        signals = pd.Series(0, index=features.index)\n",
    "        \n",
    "        # Buy when price above 20-day MA and RSI < 70\n",
    "        # Sell when price below 20-day MA and RSI > 30\n",
    "        current_prices = close_prices.reindex(features.index)\n",
    "        \n",
    "        buy_condition = (current_prices > features['sma_20']) & (features['rsi_14'] < 70)\n",
    "        sell_condition = (current_prices < features['sma_20']) & (features['rsi_14'] > 30)\n",
    "        \n",
    "        signals[buy_condition] = 1\n",
    "        signals[sell_condition] = -1\n",
    "        \n",
    "        print(f\"✓ Generated signals for {len(signals)} days\")\n",
    "        print(f\"✓ Buy signals: {(signals == 1).sum()}\")\n",
    "        print(f\"✓ Sell signals: {(signals == -1).sum()}\")\n",
    "        print(f\"✓ Hold signals: {(signals == 0).sum()}\")\n",
    "        print(f\"✓ Latest signal: {signals.iloc[-1]} ({'BUY' if signals.iloc[-1] == 1 else 'SELL' if signals.iloc[-1] == -1 else 'HOLD'})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Signal generation failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 5: Test Simple Backtest\n",
    "    print(\"\\n5. Testing Simple Backtest...\")\n",
    "    try:\n",
    "        # Align data\n",
    "        common_idx = signals.index.intersection(current_prices.index)\n",
    "        test_signals = signals[common_idx].values\n",
    "        test_prices = current_prices[common_idx].values\n",
    "        test_dates = common_idx\n",
    "        \n",
    "        # Simple backtest calculation\n",
    "        returns = np.diff(test_prices) / test_prices[:-1]\n",
    "        strategy_returns = test_signals[:-1] * returns  # Use signal to get next day's return\n",
    "        \n",
    "        # Calculate cumulative returns\n",
    "        cum_returns = np.cumprod(1 + strategy_returns)\n",
    "        total_return = (cum_returns[-1] - 1) * 100\n",
    "        \n",
    "        # Calculate some basic metrics\n",
    "        sharpe = np.mean(strategy_returns) / np.std(strategy_returns) * np.sqrt(252) if np.std(strategy_returns) > 0 else 0\n",
    "        max_dd = np.max(np.maximum.accumulate(cum_returns) - cum_returns) / np.maximum.accumulate(cum_returns).max() * 100\n",
    "        \n",
    "        print(f\"✓ Backtest completed over {len(strategy_returns)} days\")\n",
    "        print(f\"✓ Total Return: {total_return:.2f}%\")\n",
    "        print(f\"✓ Sharpe Ratio: {sharpe:.2f}\")\n",
    "        print(f\"✓ Max Drawdown: {max_dd:.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Backtesting failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 6: Test Position Check\n",
    "    print(\"\\n6. Testing Position Management...\")\n",
    "    try:\n",
    "        current_position = trader.get_current_position(test_symbol)\n",
    "        print(f\"✓ Current position in {test_symbol}: {current_position} shares\")\n",
    "        \n",
    "        # Test getting account positions\n",
    "        positions = trader.api.list_positions()\n",
    "        print(f\"✓ Total open positions: {len(positions)}\")\n",
    "        \n",
    "        if len(positions) > 0:\n",
    "            for pos in positions[:3]:  # Show first 3 positions\n",
    "                print(f\"  - {pos.symbol}: {pos.qty} shares, P&L: ${float(pos.unrealized_pl):.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Position check failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 7: Test Market Hours\n",
    "    print(\"\\n7. Testing Market Status...\")\n",
    "    try:\n",
    "        clock = trader.api.get_clock()\n",
    "        print(f\"✓ Market is {'OPEN' if clock.is_open else 'CLOSED'}\")\n",
    "        print(f\"✓ Next open: {clock.next_open}\")\n",
    "        print(f\"✓ Next close: {clock.next_close}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Market status check failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓ ALL TESTS PASSED! Your trading system is working correctly.\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Implement your full technical indicators\")\n",
    "    print(\"2. Add your ML model for signal generation\")\n",
    "    print(\"3. Test with small position sizes\")\n",
    "    print(\"4. Monitor performance and logs\")\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING CORE TRADING SYSTEM\n",
      "============================================================\n",
      "\n",
      "1. Testing Alpaca Connection...\n",
      "✓ Alpaca connection successful!\n",
      "✓ Account Status: ACTIVE\n",
      "✓ Buying Power: $200,000.00\n",
      "\n",
      "2. Testing Historical Data Retrieval...\n",
      "✓ Retrieved 2514 days of data for AAPL\n",
      "✓ Date range: 2015-08-18 to 2025-08-15\n",
      "✓ Latest price: $231.59\n",
      "✓ Data type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "3. Testing Basic Feature Creation...\n",
      "✓ Created 5 basic features\n",
      "✓ Feature data shape: (2465, 5)\n",
      "✓ Latest RSI: 68.05\n",
      "\n",
      "4. Testing Signal Generation...\n",
      "✓ Generated signals for 2465 days\n",
      "✓ Buy signals: 965\n",
      "✓ Sell signals: 699\n",
      "✓ Hold signals: 801\n",
      "✓ Latest signal: 1 (BUY)\n",
      "\n",
      "5. Testing Simple Backtest...\n",
      "✓ Backtest completed over 2464 days\n",
      "✓ Total Return: 714.15%\n",
      "✓ Sharpe Ratio: 1.00\n",
      "✓ Max Drawdown: 19.61%\n",
      "\n",
      "6. Testing Position Management...\n",
      "✓ Current position in AAPL: 0.0 shares\n",
      "✓ Total open positions: 0\n",
      "\n",
      "7. Testing Market Status...\n",
      "✓ Market is CLOSED\n",
      "✓ Next open: 2025-08-18 09:30:00-04:00\n",
      "✓ Next close: 2025-08-18 16:00:00-04:00\n",
      "\n",
      "============================================================\n",
      "✓ ALL TESTS PASSED! Your trading system is working correctly.\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "1. Implement your full technical indicators\n",
      "2. Add your ML model for signal generation\n",
      "3. Test with small position sizes\n",
      "4. Monitor performance and logs\n"
     ]
    }
   ],
   "source": [
    "success = test_trading_system()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
